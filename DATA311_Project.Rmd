---
title: "DATA311_Project"
author: "Parsa Rajabi, Chelsey Hvingelby, Mackenzie Salloum, Cameron Chong, Jeff Bulmer"
date: '2019-03-31'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(boot)
```

```{r}
admissionsData <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (admissionsData)
attach(admissionsData)
#Admission_Predict_Ver1.1 <- read.csv("~/Google Drive/Year 3 - S2 Class Files/DATA 311/Project/graduate-admissions/Admission_Predict_Ver1.1.csv")
#View(Admission_Predict_Ver1.1)
```

## With Response Variable Chance.of.Admit

The variable we are interested in predicting, Chance.of.Admit, is the 9th variable.  

Run PCA on the data and remove the response variable (chance of admit) and the unique identifier (serial number)
```{r}
set.seed(43849)
pca.admin <- prcomp(as.matrix(admissionsData[,-c(1,9)]), scale = TRUE)
summary(pca.admin)
```

To choose the number of principal components to keep, we can either use the Kaiser criterion, cumulative proportion/percent of variance, or a scree plot.  

Using the Kaiser criterion, we keep all principal components with a standard deviation greater than 1 (since the data is scaled).  Hence the Kaiser criterian is telling us to keep the first principal component.  

I will now compare this with a scree plot.  
```{r}
plot(pca.admin, type="lines")
```

The above scree plot plots the monotonically decreasing eigenvalues and the location of an 'elbow' or plateau indicates the number of principal components.  The scree plot suggests probably 2 principal components.

The first two principal components that will be retained explain 78% of the variation in the data.  We can now view the data projected onto the components using a biplot.  

```{r}
biplot(pca.admin)
```


```{r}
plot(pca.admin$x[,1:2])
```

We can put data labels on the biplot by observation number 
```{r}
plot(pca.admin$x[,1:2], type = "n")
text(pca.admin$x[,1:2], labels = 1:nrow(admissionsData))
```

It looks like there are two groups in the above principal component plots.  


Take a look at the component loadings (eigenvectors) which provide the coefficients of the original variables, rounded to 2 decimal places.
```{r}
round(pca.admin$rotation[,1:2], 2)
```

These are the coefficients of the original variables.  The magnitudes are pretty similar for the first component, perhaps with the exception of research.  They are also all containing the same sign.  This is a little difficult to interpret, but most likely indicates that the first principal component is equally weighting all predictor variables, with the exception of research.  

In the second component, the highest magnitude is the research aspect, along with the letter of recommendation. Perhaps this component indicates previous experience a student has.  A reference letter most likely comes from someone you have worked with, conducted research with, volunteered with, or TA'd for.  Therefore a good reference letter coupled with research experience could be indicative of research and other activities in both academic and non-academic settings.  


We can now look at the four students who scored highest on PC1: 
```{r}
admissionsData[order(pca.admin$x[,1], decreasing = TRUE)[1:4],1:9]
```

It is noted that the four students who performed highest on PC1 all had a low belief of their chance of admit.  None of them had research, and all had a similar cumulative GPA.  In addition, the universities where all rated low (1 to be exact) and the students had similar GRE and TOEFL scores (well below the average).  These students in general seem to be ones who are not performing scoring very well across all predictors.  

And the four students who scored highest on PC2:
```{r}
admissionsData[order(pca.admin$x[,2], decreasing = TRUE)[1:4], 1:9]
```

Notice that the four students who performed highest on PC2 all have research experience.  In general, these students are scoring better than the students in principal component 1 across the board.


## With Response Variable Research

The variable we are interested in predicting, Chance.of.Admit, is the 8th variable.  

Run PCA on the data and remove the response variable (research) and the unique identifier (serial number)
```{r}
set.seed(43849)
pca.admin2 <- prcomp(as.matrix(admissionsData[,-c(1,8)]), scale = TRUE)
summary(pca.admin2)
```

To choose the number of principal components to keep, we can either use the Kaiser criterian, cumulative proportion/percent of variance, or a scree plot.  

Using the Kaiser criterian, we keep all principal components with a standard deviation greater than 1 (since the data is scaled).  Hence the Kaiser criterian is telling us to keep the first principal component.  

I will now compare this with a scree plot.  
```{r}
plot(pca.admin2, type="lines")
```

The above scree plot plots the monotonically decreasing eigenvalues and the location of an 'elbow' or plateau indicates the number of principal components.  The scree plot suggests probably 2 principal components.

The first two principal components that will be retained explain 84% of the variation in the data.  We can now view the data projected onto the components using a biplot.  

```{r}
biplot(pca.admin2)
```


```{r}
plot(pca.admin2$x[,1:2])
```

We can put data labels on the biplot by observation number 
```{r}
plot(pca.admin2$x[,1:2], type = "n")
text(pca.admin2$x[,1:2], labels = 1:nrow(admissionsData))
```

It looks like there are two groups in the above principal component plots.  


Take a look at the component loadings (eigenvectors) which provide the coefficients of the original variables, rounded to 2 decimal places.
```{r}
round(pca.admin2$rotation[,1:2], 2)
```

These are the coefficients of the original variables.  The magnitudes are extremely similar for the first component.  They are also all containing the same sign.  This is a little difficult to interpret again, but most likely indicates that the first principal component is equally weighting all predictor variables.  

In the second component, the highest magnitude is the lettor of recommendation which has a negative sign.  Other variables with the same sign include the SOP score and the university rating.  Variables of opposite sign with higher magnitude include GRE Score, TOEFL Score, as well as CGPA and Chance of Admit having a lower magnitude.  Students who score high on this principal component, likely scored high on their standardized tests.  


We can now look at the four students who scored highest on PC1: 
```{r}
admissionsData[order(pca.admin2$x[,1], decreasing = TRUE)[1:4],1:9]
```

The top four students in this first principal component are the same as the first four students in the previous PC1 (compared using Serial.No.).  Even when looking at the loadings, this principal component is very similar to the principal component in the previous section.  

And the four students who scored highest on PC2:
```{r}
admissionsData[order(pca.admin2$x[,2], decreasing = TRUE)[1:4], 1:9]
```

As hypothesized above, the first four students in PC2 are scoring higher on their standardized tests (GRE.Score and TOEFL.Score).  These students are performing the at, or above average on these standardized tests.  However, they all have a below average score on SOP, and LOR.  The CGPA of the students scoring high on PC2 hovers fairly close to the mean.  This proves the initial hypothesis that standardized testing is most important for PC2.  


##Logmod Analysis and Plots
Here's a logmod analysis. No variable selection performed though.

```{r}
University.Rating <- factor(University.Rating)
Research <- factor(Research)
logmod <- glm(University.Rating ~., data=admissionsData)
summary(logmod)
plot(logmod)

linear.full <- lm(Chance.of.Admit ~., data=admissionsData)
linear.null <- lm(Chance.of.Admit ~ 1, data=admissionsData)

linear.rank.full <- lm(University.Rating ~., data=admissionsData)
linear.null.full <- lm(University.Rating ~ 1, data=admissionsData)

```
<<<<<<< HEAD

##Linear Regression and some plots
=======
>>>>>>> chelsey



##Linear Regression and some plots
Here's a linear model with a few plots.

```{r}
linear <- lm(Chance.of.Admit ~., data=admissionsData)
summary(linear)
plot(linear)
```

```{r, include=FALSE}
# Other useful functions 
coefficients(linear) # model coefficients
confint(linear, level=0.95) # CIs for model parameters 
fitted(linear) # predicted values
residuals(linear) # residuals
anova(linear) # anova table 
vcov(linear) # covariance matrix for model parameters 
influence(linear) # regression diagnostics
```

#Variable Selection for Chance of Admittion

By performing backwards selection, we will remove the least significant values until all values are significant.
```{r}
linear <- lm(Chance.of.Admit~ ., data = admissionsData )
summary(linear)

#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = admissionsData )
summary(linear)


#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = admissionsData )
#All variables are now significant
summary(linear)
```

#CV for linear model - Chance of Admission
```{r,, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
coef <-matrix(nrow = 500, ncol=length(linear$coefficients))
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
#coef[[i]] <- cvlm[[i]]$coefficients
  for(j in 1:length(linear$coefficients)){
    coef[i,j] <- cvlm[[i]]$coefficients[j]
  }
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
#The chance of being admitted to univeristy is +/- 6.66%.   
<!---Check this conclusion. Not certain this is quite right. You also may have missed a - in the msecv command -->

<!--#Bootstrap for linear model - Chance of Admission-->
```{r, include=FALSE, eval=FALSE, warning=FALSE}
newboots <- list()
bootsmod <- list()
msebs <- NA
B <- 5000
bootcoef <- matrix(nrow = B, ncol=length(linear$coefficients))
for(i in 1:B){
  newboots[[i]] <- test[sample(1:nrow(admissionsData), nrow(admissionsData), replace=TRUE),]
  bootsmod[[i]] <- lm(University.Rating~., data=newboots[[i]])
  for(j in 1:length(linear$coefficients)){
    bootcoef[i,j] <- bootsmod[[i]]$coefficients[j]
  }
  #msebs[i] <- (predict(bootsmod[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
}
summary(linear)$coefficients[,2]
c(sd(bootcoef[,1]),sd(bootcoef[,2]),sd(bootcoef[,3]),sd(bootcoef[,4]),sd(bootcoef[,5]),sd(bootcoef[,6]),sd(bootcoef[,7]))
c(sd(coef[,1]),sd(coef[,2]),sd(coef[,3]),sd(coef[,4]),sd(coef[,5]),sd(coef[,6]),sd(coef[,7])) 

```

#Variable Selection for Research 

```{r}
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP +LOR + CGPA, data = admissionsData )
#summary(linear)

#Remove LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR + CGPA, data = admissionsData )
summary(linear)

#Remove CGPA
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR, data = admissionsData )
summary(linear)

#Remove LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating, data = admissionsData )
summary(linear)

#Remove TOEFL
linear <- lm(Research~ Serial.No. + GRE.Score + University.Rating, data = admissionsData )
summary(linear)

#Remove Serial Number
linear <- lm(Research~ + GRE.Score + University.Rating, data = admissionsData )
summary(linear)

```

#CV for linear model - Research
```{r,, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(Research[-i] ~ GRE.Score[-i] + University.Rating[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(GRE.Score[-i] + University.Rating[-i]))-Research[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```

<<<<<<< HEAD
<!--##Classification

How about some Classification?
Let's try knn
-->
=======

#Variable Selection for University Ranking
```{r}
linear <- lm(University.Rating~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove Serial Number
linear <- lm(University.Rating~  GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove GRE
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove Research
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA, data = admissionsData )
summary(linear)
```

#CV for linear model - University Rating
```{r,warning=FALSE}
set.seed(7861)
>>>>>>> chelsey

cvlm <- list()
msecv <- NA
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(University.Rating[-i] ~ TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i]))-University.Rating[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```

