---
title: "DATA311_Project"
author: "Parsa"
date: '2019-03-07'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
```

```{r}
test <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (test)
head(test)


linear.full <- lm(Chance.of.Admit ~., data=test)
linear.null <- lm(Chance.of.Admit ~ 1, data=test)

linear.rank.full <- lm(University.Rating ~., data=test)
linear.null.full <- lm(University.Rating ~ 1, data=test)

```




##Linear Regression and some plots
Here's a linear model with a few plots.

```{r}
linear <- lm(Chance.of.Admit ~., data=test)
summary(linear)
plot(linear)
```
```{r}
linear <- lm(University.Rating ~., data=test)
summary(linear)
plot(linear)
```

By performing backwards selection, we will remove the least significant values until all values are significant.

```{r}
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + University.Rating )
summary(linear)

#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research )
summary(linear)


#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research )
#All variables are now significant
summary(linear)

```



