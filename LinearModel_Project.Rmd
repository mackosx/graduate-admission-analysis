---
title: "LinearModel_Project"
author: "Parsa"
date: '2019-03-30'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
test <- read.csv("Admission_Predict_Ver1.1.csv")
summary (test)
head(test)
attach(test)

#Linear Regression and some plots

#Here's a linear model (Chance of Admit)
linear <- lm(Chance.of.Admit ~., data=test)
summary(linear)
plot(linear)

logmod <- glm(Research~., data=test)
summary(logmod)
plot(logmod)

#chance.vs.CGPA <- lm(test$Chance.of.Admit ~ test$CGPA)
#plot(test$Chance.of.Admit ~ test$CGPA, xlab = "Chance of Admission", ylab = "CGPA", main = "Chance of Admission VS CGPA")
#abline(chance.vs.CGPA , col="red", lwd=3, data = test)
```


#Variable Selection for Chance of Admittion
By performing backwards selection, we will remove the least significant values until all values are significant.
```{r}
linear <- lm(Chance.of.Admit~ ., data = test )
#summary(linear)

#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = test )
#summary(linear)


#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = test )
#All variables are now significant

summary(linear)
plot(linear)
```



#Variable Selection for Research 
```{r}
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP +LOR + CGPA, data = test )
#summary(linear)

#Remove SOP
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR + CGPA, data = test )
#summary(linear)

#Remove SOP, CGPA
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR, data = test )
#summary(linear)

#Remove SOP, CGPA, LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating, data = test )
#summary(linear)

#Remove SOP, CGPA, LOR, TOEFL
linear <- lm(Research~ Serial.No. + GRE.Score + University.Rating, data = test )
#summary(linear)

#Remove SOP, CGPA, LOR, TOEFL, Serial Number
linear <- lm(Research~ + GRE.Score + University.Rating, data = test )
summary(linear)
plot(linear)

```

#Variable Selection for University Ranking
```{r}
linear <- lm(University.Rating~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = test )
summary(linear)

#Remove Serial Number
linear <- lm(University.Rating~  GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = test )
summary(linear)

#Remove GRE
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA + Research, data = test )
summary(linear)

#Remove Research
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA, data = test )
summary(linear)
```

#LogMod Backwards Selection for Research since it's a binary variable:
```{r}
logmod <- glm(Research~., data=test)
summary(logmod)
plot(logmod)

#Removed LOR
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP + CGPA, data=test)
summary(logmod)
#plot(logmod)

#Removed LOR, CGPA
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP , data=test)
summary(logmod)

#Removed LOR, CGPA, TOEFL
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating + SOP , data=test)
summary(logmod)

#Removed LOR, CGPA, TOEFL, SOP
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating , data=test)
summary(logmod)

#Removed LOR, CGPA, TOEFL, SOP, Serial Number
logmod <- glm(Research~ GRE.Score  + University.Rating , data=test)
summary(logmod)
#plot(logmod)
```
#based on the logMod summary, the 2 most signifant variables are University Rating and GRE.Score. 



#CVs

#CV for linear model - Chance of Admittion - Manual Leave on Out
```{r, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
  #Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame( GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
#CV for linear model - Chance of Admittion vs CGPA
```{r, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
  #Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~  CGPA[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(CGPA[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
#Missclassification Rate - Research 
```{r, warning=FALSE}
ResearchData <- test$Research
ResearchDataFactor <- factor(test$Research)

simlog<-glm(factor(Research)~., family = "binomial", data = test)
table(predict(simlog, type = "response")>0.5, ResearchData)

misclassificationRate <- (57+66)/(154+223)
capture.output(cat('Misclassification rate = ', misclassificationRate))

library(MLmetrics)

F1<- F1_Score(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Accu <- Accuracy(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Sens <- Sensitivity(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)

scoreTable <-cbind(F1, Accu, Sens, misclassificationRate)
colnames(scoreTable)<-c("F1 Score", "Accuracy", "Sensitivity", "Misclassification")
rownames(scoreTable)<-c("Logistic Regression")
#rownames(scoreTable)<-c("Logistic Regression", "Neural Network")
round(scoreTable,3)

```

#CV for linear model - University Rating - Manual Leave on Out
```{r, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
  #Fit the linear model
cvlm[[i]] <- lm(University.Rating[-i] ~ TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i]))-University.Rating[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
