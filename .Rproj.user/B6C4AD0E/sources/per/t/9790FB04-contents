---
title: "Assignment 4"
author: "Parsa Rajabi 46418166"
date: '2019-03-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#1
1. In base R there is a data set called ‘animals’. Check the help file for its description — it is binary data. Install/load the ‘cluster’ and ‘mclust’ libraries. Binary data is tricky to visualize, but luckily we’ve learned one way to do so!

(a) Start by calculating a pairwise distance matrix. Use the ‘daisy’ command from the ‘cluster’ library. You should receive a warning, out of laziness we will leave it alone — but note that you could/should let the algorithm know that it is binary data, and you could further specify for each variable whether you want to treat it in symmetric or asymmetric fashion. Also note that this function can perform Gowers distance for mixed data.

```{r}
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
```


(b) Now use ‘cmdscale’ to provide a 2D mapping of the original data. Plot the data, but make the row names of the data the symbols rather than the traditional dots. (Hint, start by plot(..., type=“n”) then use text(..., rownames(...))). What do you notice?

```{r}
animalsDist<-cmdscale(dAnimals) 
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
```

##Note that 3 pairwise distances are essentially the same (indicated by the overlapping of labels).

(c) Use set.seed(413) and kmeans to perform clustering with 3 groups. Provide a table of the animal type and clustering results.


```{r}
#head(animals)
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster) #points(kAnimals$centers, col = 1:3, pch=8, cex=2)
kAnimals2<-kmeans(animalsDist, 3) 
plot(animalsDist, col = kAnimals2$cluster) 
points(kAnimals2$centers, col = 1:3, pch=8, cex=2)
#kAnimals2$cluster
table(rownames(animals), kAnimals2$cluster)
```

#2
2. On connect, you will find a data set called “car93”. It is a cleaned up version of the “Cars93” data in the “MASS” library.
##2a
(a) Perform a principal components analysis on the numeric variables within the car93 data set. Provide a summary of the fitted model and a biplot. Ensure you scale the data.
```{r}
card <- read.csv("car93.csv", stringsAsFactors = FALSE)
pcard <- prcomp(as.matrix(card[,-c(1,2,3,4)]), scale.=TRUE)
summary(pcard)
biplot(pcard)
```


##2b
(b) Interpret the loadings of the first principal component.
--
```{r}
round(carPCA$rotation[,1],2)
```
<!-- hehexd AS -->

The first principal component is made up of a relatively equal weight of all the variables. However, MPG ratings, RPM, and Rev.per.mile are all negatively associated with the first component. We can somewhat view this component as a measure of the ‘size’ of the car, since large cars will have high scores on all the positively correlated variables and smaller scores on the four negatively associated variables.

<!-- hehexd ES -->
Based on the loading of PC1, there is a positive correlation with Price, Space, Weight, Engine Size, Wheelbase, Horse power, width and turn circle. Negative correlations seem to relate to fuel efficiency (MPG), rev.per.miles, and RPM. I would assume that PC1 relates to the size of the car.

##2c
(c) Interpret the loadings of the second principal component.

```{r}
round(carPCA$rotation[,2],2)
```

<!-- hehexd ES -->
Price, rev.per.miles, fuel.tank.capacity, weight, horsepower, and RPM all have a positive coefficient. MPG city, MPG highway, Engine Size, Wheelbase, Rear.seat.room, Luggage.room, length, width, and turn.circle have negative coefficients. I would assume that based on the loading of the second PC it is related to the
‘sportiness’/luxuriness of the car.

##2d
(d) How many principal components should be kept...
i. according to the Kaiser criterion? 
2 PCs 

ii. if we wish to retain at least 90% of the variance in the data?
5 PCs

iii. according to the scree plot?
2 PCs (1 or 3 are probably arguable as well)

```{r}
plot(pcard, type="lines", main="Scree Plot")
```
    
    
##2e
(e) Keep the components suggested by the Kaiser criterion and...
i. perform LDA (with built-in leave-one-out cross-validation) with our response be- ing “Small” or “Not Small” for the “Type” of car and the predictors being the components retained. What is the cross-validated logloss of this model?
ii. perform LDA (with built-in leave-one-out cross-validation) using all categories from the original “Type” variable as the response. What is the cross-validated logloss of this model?


```{r}
car<-read.csv("car93.csv")
#car93<-read.csv("car93.csv") 
library(MASS)
library(gclus)
library(MLmetrics)

for(i in 1:nrow(car93[,3])){ if(car93[i,3]!="Small"){
    car93[i,3] <- "Not Small"
  }
}
car93$Type<-factor(car93$Type)
carLDA<-lda(carPCA$x[,1:2], car93$Type, data = car93,CV=TRUE) table(car93$Type, carLDA$class)

LogLoss(carLDA$posterior[,2], as.numeric(car93$Type)-1)
carLDA2<-lda(carPCA$x[,1:2], car$Type, data = car,CV=TRUE)
table(car$Type, carLDA2$class)
LogLoss(carLDA2$posterior[,2], as.numeric(car$Type)-1)
```



##2f
(f) Do the results from the above classification runs approximately match the discus- sion surrounding the interpretation of the first and/or second principal components? Explain.
 
#3
 3. Fit a neural network on the car93 data set with one hidden layer and 5 hidden layer variables to predict car price using all other quantitative variables. In order to provide a proper fit, you will need to normalize the variables (this is pretty common for NNs, though we didn’t touch on it in class). If you have an R object called car numeric, which contains only the quantitative data, then we can use the following command to quickly normalize:
scar <- apply(car numeric, 2, function(v) (v-min(v))/(max(v)-min(v)))
Use set.seed(4521) prior to the model fitting.

##3a

(a) Provide the MSE of this model.
```{r}
library(neuralnet)
car_numeric <- card[,-c(1,2,3,4)]
scar <- apply(car_numeric, 2, function(v) (v-min(v))/(max(v)-min(v)))
set.seed(4521)
nncar <- neuralnet(paste("Price~", paste(colnames(scar)[-1],collapse=" + ")), data=scar, linear.output = TRUE, hidden=5)
res <- compute(nncar, scar[,-c(1)])
mse <- mean((scar[,1]-res$net.result)^2)
mse
```


##3b
(b) Of course, this could be overfitting, let’s set up a training and testing scenario.
set.seed(217)
ind <- sample(1:nrow(scar), 41)
train <- scar[ind,]
test <- scar[-ind,]
Now fit the same neural network, then find the MSE for the test set.

```{r}
 set.seed(217)
ind <- sample(1:nrow(scar), 41)
train <- scar[ind,]
test <- scar[-ind,]
nncar <- neuralnet(paste("Price~", paste(colnames(scar)[-1],collapse=" + ")), data=train, linear.output = TRUE, hidden=5)
yhat <- compute(nncar, test[,-1])
mse <- mean((yhat$net.result-test[,1])^2)
mse
```


##3c 
(c) On average, how far off is your model in its prediction of price? Give me this amount in dollars.
```{r}
#first get my predictions back to the original scale
osyhat <- yhat$net.result*(max(card$Price)-min(card$Price)) + min(card$Price) #then use the indexing from my training/testing set on the original price
osy <- card$Price[-ind]
#now find, on average, how far away are we
mean(abs(osyhat-osy))
#[1] 5.567321972
#and note that these prices are in THOUSANDS of dollars
```
So, on average, we predict this model will be about $5,567 off.

