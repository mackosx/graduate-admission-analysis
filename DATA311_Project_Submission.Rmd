---
title: "DATA311_Project_Submission"
author: "Jeff B"
date: "March 25, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(mvtnorm)
library(mclust)
library(cluster)
library(fpc)
```

First, let's take a look at our data
```{r}
test <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (test)
head(test)
attach(test)
plot(test)
```

### Clustering

Naively, we can start by computing the respective pairwise distances, and try k-means clustering 
```{r}
dg<-daisy(test, metric="gower")
pdist <- cmdscale(d=dg)
plot(pdist)
```

Two clear groups appear, so we can use k-means clustering with $k=2$ to try and get those
```{r}
#set.seed(413)
km <- kmeans(pdist, centers = 2)
plotcluster(pdist, km$cluster)
```

That doesn't get us the groups we expect, so we can try hierarchical clustering instead.

```{r}
length(pdist)
```
```{r}
hms <- hclust(na.omit(dg), method="single")
pairs(pdist, col=cutree(hms,2))
#plot(pdist)
```
With hierarchical clustering, we can get the groups we expect using single linkage chaining. Since this was a naive attempt using all variables, let's see if we can determine what actually affects which data goes into which cluster. 
```{r}
pairs(test, col=cutree(hms,2))
```
We notice that, using the single linkage chaining from above, we can predict whether or not a student performs research almost perfectly. Additionally, we get decent results pertaining to the Chance of Admission and the GRE Score. Based on these clustering results, our two groups (Research and Non-Research) divide up pretty well as follows: In general, Research has a higher chance of admission than Non-Research, as well as a higher GRE and TOEFL score. 

So, by applying Gower's Distance on all predictors and using single-linkage chaining, we are able to perfectly predict the presence of a Research variable. However, since our model predicts with 100% accuracy, this is almost certainly overfitting the data. So next we'll split our data into training and testing data and see how we do.
```{r}
smp_size <- floor(0.6 * nrow(test))

train_ind <- sample(seq_len(nrow(test)), size = smp_size)

testtrain <- test[train_ind, ]
testtest <- test[-train_ind, ]

dgt<-daisy(testtrain, metric="gower")
hms <- hclust(na.omit(dgt), method="single")
predict(cutree(hms, 2), data=testtest)
```



