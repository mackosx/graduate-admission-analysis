---
title: "DATA311_Project"
author: "Parsa Rajabi, Chelsey Hvingelby, Mackenzie Salloum, Cameron Chong, Jeff Bulmer"
date: '2019-03-31'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(mvtnorm)
library(mclust)
library(cluster)
library(fpc)
library(boot)
library(tree)
library(MASS)
library(randomForest)
```

### Introduction

```{r, echo=FALSE}
admissionsData <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (admissionsData)
attach(admissionsData)
#Admission_Predict_Ver1.1 <- read.csv("~/Google Drive/Year 3 - S2 Class Files/DATA 311/Project/graduate-admissions/Admission_Predict_Ver1.1.csv")
#View(Admission_Predict_Ver1.1)
head(admissionsData[,-1])
```

Data was collected from 500 prospective graduate students, including various scores achieved in the Test of English as a First Language (TOEFL) and Graduate Record Examinations (GRE), the strength of each candidates Statement of Purpose (SOP) and Letter of Recommendation (LOR), Undergraduate GPA (CGPA), and Research Experience. Finally, each candidate was polled about their confidence of being accepted into graduate school (Chance of Admit). 

Using this data, we will perform analyses to attempt to predict variables within the dataset. The most obvious candidate for prediction is Chance of Admit, however, it may be worthwhile to attempt to predict other variables. In order to determine this, we will first run clustering on the dataset to see if any clear groups appear.

### Clustering

We begin by computing the respective pairwise distances in our data, and plotting the output.

```{r, echo=FALSE}
dg<-daisy(admissionsData, metric="gower")
pdist <- cmdscale(d=dg)
plot(pdist)
```

We quickly see that two clear groups appear. We can isolate these two groups using hierarchical clustering with single-linkage chaining. 

```{r, , echo=FALSE, eval=FALSE}
set.seed(413)
km <- kmeans(pdist, centers = 2)
#plotcluster(pdist, km$cluster)
```

```{r, echo=FALSE}
hms <- hclust(na.omit(dg), method="single")
#plot(hms)
pairs(pdist, col=cutree(hms,2))
#plot(pdist)
```

We can then use scatterplots to show the entirety of the data, while still keeping the groups intact, to see if we can determine which predictors most affect these clusters.


```{r, echo=FALSE}
pairs(admissionsData, col=cutree(hms,2))
```

We notice that, using the single linkage chaining from above, we can predict whether or not a student performs research almost perfectly.

So, by applying Gower's Distance on all predictors and using single-linkage chaining, we have two clear clusters directly coinciding with the presence of a research variable. This tells us that we should use Research as a response variable in models, in addition to Chance of Admit.

We can now perform analyses on the data to attempt to predict a candidate's Chance of Admission, as well as the presence of Research Experience. 

### Principal Component Analysis

Now that we've determined our response variables of interest using clustering, we can run Principal Component Analysis to further our understanding of our data. 

## With Response Variable Chance.of.Admit

First, let's consider principal components in the context of predicting Chance of Admission.

```{r, echo=FALSE}
set.seed(43849)
#remove Chance.of.Admit (Response variable, position 9) and Serial.No (unique identifier, position 1)
pca.admin <- prcomp(as.matrix(admissionsData[,-c(1,9)]), scale = TRUE)
summary(pca.admin)
```

Using the Kaiser criterion, we keep all principal components with a standard deviation greater than 1 (since the data is scaled).  Hence the Kaiser criterian tells us to keep the first principal component.  

Comparing this with a scree plot.  
```{r, echo=FALSE}
plot(pca.admin, type="lines")
```

The above scree plot shows the monotonically decreasing eigenvalues and the location of an 'elbow' or plateau indicates the number of principal components. The scree plot suggests 2 principal components.

The first two principal components that will be retained explain 78% of the variation in the data.  We can now view the data projected onto the components using a biplot.  

```{r, echo=FALSE}
biplot(pca.admin)
```


```{r, echo=FALSE, eval=FALSE}
plot(pca.admin$x[,1:2])
```

If we plot out our data, with PC1 on the x axis and PC2 on the y axis, we get the following plot
```{r, echo=FALSE}
plot(pca.admin$x[,1:2], type = "n")
text(pca.admin$x[,1:2], labels = 1:nrow(admissionsData))
```

There appear to be two groups in the principal component plots. This is unsurprising, considering the Principal Components are an orthogonal rotation of the original data, which could also be modelled as two groups. 


We can next look at the component loadings (eigenvectors) which provide the coefficients of the original variables, rounded to 2 decimal places.
```{r, echo=FALSE}
round(pca.admin$rotation[,1:2], 2)
```

These are the coefficients of the original variables.  The magnitudes are pretty similar for the first component, perhaps with the exception of research.  They are also all containing the same sign.  This is a little difficult to interpret, but most likely indicates that the first principal component is equally weighting all predictor variables, with the exception of research.  

In the second component, the highest magnitude is the research aspect, along with the letter of recommendation. Perhaps this component indicates previous experience a student has.  A reference letter most likely comes from someone you have worked with, conducted research with, volunteered with, or TA'd for.  Therefore a good reference letter coupled with research experience could be indicative of research and other activities in both academic and non-academic settings.  


We can now look at the four students who scored highest on PC1: 
```{r, echo=FALSE}
admissionsData[order(pca.admin$x[,1], decreasing = TRUE)[1:4],1:9]
```

It is notable that the four students who performed highest on PC1 all had a low belief of their chance of admit.  None of them had research, and all had a similar cumulative GPA.  In addition, the universities where all rated low (1 to be exact) and the students had similar GRE and TOEFL scores (well below the average).  These students in general seem to be ones who are not performing scoring very well across all predictors.  

And the four students who scored highest on PC2:
```{r, echo=FALSE}
admissionsData[order(pca.admin$x[,2], decreasing = TRUE)[1:4], 1:9]
```

Notice that the four students who performed highest on PC2 all have research experience.  In general, these students are scoring better than the students in principal component 1 across the board.


## With Response Variable Research

Now, we consider running Principal Component Analysis while considering Research as our response variable. 

```{r, echo=FALSE}
set.seed(43849)
pca.admin2 <- prcomp(as.matrix(admissionsData[,-c(1,8)]), scale = TRUE)
summary(pca.admin2)
```

Using the Kaiser criterion, we would keep only the first principal component.  

```{r, echo=FALSE}
plot(pca.admin2, type="lines")
```

Looking at the above scree plot, we would keep 2 principal components.

The first two principal components that will be retained explain 84% of the variation in the data.  We can now view the data projected onto the components using a biplot.  

```{r, echo=FALSE}
biplot(pca.admin2)
```


```{r, eval=FALSE, echo=FALSE}
plot(pca.admin2$x[,1:2])
```

```{r, echo=FALSE}
plot(pca.admin2$x[,1:2], type = "n")
text(pca.admin2$x[,1:2], labels = 1:nrow(admissionsData))
```

Again, we see the presence of two groups. 



We can now look at the loadings for each Principal Component, rounded to 2 decimal places. 
```{r, echo=FALSE}
round(pca.admin2$rotation[,1:2], 2)
```

These are the coefficients of the original variables.  The magnitudes are extremely similar for the first component.  They are also all containing the same sign.  This is a little difficult to interpret again, but most likely indicates that the first principal component is equally weighting all predictor variables.  

In the second component, the highest magnitude is the lettor of recommendation which has a negative sign.  Other variables with the same sign include the SOP score and the university rating.  Variables of opposite sign with higher magnitude include GRE Score, TOEFL Score, as well as CGPA and Chance of Admit having a lower magnitude.  Students who score high on this principal component, likely scored high on their standardized tests.  


We can now look at the four students who scored highest on PC1: 
```{r, echo=FALSE}
admissionsData[order(pca.admin2$x[,1], decreasing = TRUE)[1:4],1:9]
```

The top four students in this first principal component are the same as the first four students in the previous PC1 (compared using Serial.No.).  Even when looking at the loadings, this principal component is very similar to the principal component in the previous section.  

And the four students who scored highest on PC2:
```{r, echo=FALSE}
admissionsData[order(pca.admin2$x[,2], decreasing = TRUE)[1:4], 1:9]
```

As hypothesized above, the first four students in PC2 are scoring higher on their standardized tests (GRE.Score and TOEFL.Score).  These students are performing the at, or above average on these standardized tests.  However, they all have a below average score on SOP, and LOR.  The CGPA of the students scoring high on PC2 hovers fairly close to the mean.  This supports the initial hypothesis that standardized testing is most important for PC2.  

### Linear Models

## Logmod Analysis and Plots
Here's a logmod analysis. No variable selection performed though.

```{r, echo=FALSE}
University.Rating <- factor(University.Rating)
Research <- factor(Research)
logmod <- glm(University.Rating ~., data=admissionsData)
summary(logmod)
plot(logmod)

linear.full <- lm(Chance.of.Admit ~., data=admissionsData)
linear.null <- lm(Chance.of.Admit ~ 1, data=admissionsData)

linear.rank.full <- lm(University.Rating ~., data=admissionsData)
linear.null.full <- lm(University.Rating ~ 1, data=admissionsData)

```



## Linear Regression and some plots
Here's a linear model with a few plots.

```{r, echo=FALSE}
linear <- lm(Chance.of.Admit ~., data=admissionsData)
summary(linear)
plot(linear)
```

```{r, echo=FALSE, include=FALSE}
# Other useful functions 
coefficients(linear) # model coefficients
confint(linear, level=0.95) # CIs for model parameters 
fitted(linear) # predicted values
residuals(linear) # residuals
anova(linear) # anova table 
vcov(linear) # covariance matrix for model parameters 
influence(linear) # regression diagnostics
```

# Variable Selection for Chance of Admission

By performing backwards selection, we will remove the least significant values until all values are significant.
```{r, echo=FALSE}
linear <- lm(Chance.of.Admit~ ., data = admissionsData )
summary(linear)

#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = admissionsData )
summary(linear)


#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = admissionsData )
#All variables are now significant
summary(linear)
```

# CV for linear model - Chance of Admission
```{r,echo=FALSE, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
coef <-matrix(nrow = 500, ncol=length(linear$coefficients))
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[-i])^2
#coef[[i]] <- cvlm[[i]]$coefficients
  for(j in 1:length(linear$coefficients)){
    coef[i,j] <- cvlm[[i]]$coefficients[j]
  }
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
#The chance of being admitted to univeristy is +/- 6.66%.   
<!---Check this conclusion. Not certain this is quite right. You also may have missed a - in the msecv command -->

<!--#Bootstrap for linear model - Chance of Admission-->
```{r, include=FALSE, echo=FALSE, eval=FALSE, warning=FALSE}
newboots <- list()
bootsmod <- list()
msebs <- NA
B <- 5000
bootcoef <- matrix(nrow = B, ncol=length(linear$coefficients))
for(i in 1:B){
  newboots[[i]] <- admissionsData[sample(1:nrow(admissionsData), nrow(admissionsData), replace=TRUE),]
  bootsmod[[i]] <- lm(University.Rating~., data=newboots[[i]])
  for(j in 1:length(linear$coefficients)){
    bootcoef[i,j] <- bootsmod[[i]]$coefficients[j]
  }
  #msebs[i] <- (predict(bootsmod[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
}
summary(linear)$coefficients[,2]
c(sd(bootcoef[,1]),sd(bootcoef[,2]),sd(bootcoef[,3]),sd(bootcoef[,4]),sd(bootcoef[,5]),sd(bootcoef[,6]),sd(bootcoef[,7]))
c(sd(coef[,1]),sd(coef[,2]),sd(coef[,3]),sd(coef[,4]),sd(coef[,5]),sd(coef[,6]),sd(coef[,7])) 

```

#Variable Selection for Research 

```{r, echo=FALSE}
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP +LOR + CGPA, data = admissionsData )
#summary(linear)

#Remove LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR + CGPA, data = admissionsData )
summary(linear)

#Remove CGPA
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR, data = admissionsData )
summary(linear)

#Remove LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating, data = admissionsData )
summary(linear)

#Remove TOEFL
linear <- lm(Research~ Serial.No. + GRE.Score + University.Rating, data = admissionsData )
summary(linear)

#Remove Serial Number
linear <- lm(Research~ + GRE.Score + University.Rating, data = admissionsData )
summary(linear)

```

#CV for linear model - Research
```{r,echo=FALSE, warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(Research[-i] ~ GRE.Score[-i] + University.Rating[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(GRE.Score[-i] + University.Rating[-i]))-Research[-i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```


<!-- #Variable Selection for University Ranking
```{r}
linear <- lm(University.Rating~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove Serial Number
linear <- lm(University.Rating~  GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove GRE
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA + Research, data = admissionsData )
summary(linear)

#Remove Research
linear <- lm(University.Rating~   TOEFL.Score + SOP +LOR + CGPA, data = admissionsData )
summary(linear)
```

#CV for linear model - University Rating
```{r,warning=FALSE}
set.seed(7861)

cvlm <- list()
msecv <- NA
for(i in 1:nrow(admissionsData)){
  #Fit the linear model
cvlm[[i]] <- lm(University.Rating[-i] ~ TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(TOEFL.Score[-i] + SOP[-i] + LOR[-1] + CGPA[-i]))-University.Rating[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
```
--->
#Trees and Forests

```{r, echo=FALSE}
admissionsData <- admissionsData[,-1]
#head(admissionsData)
dim(admissionsData)
trainindex <- sample(1:nrow(admissionsData), 350)
admissionsTrain <- admissionsData[trainindex, ]
admissionsTest <- admissionsData[-trainindex, ]
```

#Chance of Admittance 
I am going to do a 70/30 split of training and testing data. There are 500 observations, so we will have 350 training observations and 150 testing points. 
```{r, echo=FALSE}

set.seed(110101010)
admissionTree <- tree(Chance.of.Admit~., data = admissionsTrain)
plot(admissionTree)
text(admissionTree, pretty=0)


admissionTreeCV <- cv.tree(admissionTree, FUN = prune.tree, K = 10)
plot(admissionTreeCV, type = "b")
admissionTreeCV

admissionTreeCV$dev
admissionTreeCV$size
which.min(admissionTreeCV$dev)
```
Cross validation suggest 7 nodes would be best, so we will prune the tree using 7 terminal nodes. 

```{r, echo=FALSE}
pruneAdmissionTreeCV <- prune.tree(admissionTree, best=7)
plot(pruneAdmissionTreeCV)
text(pruneAdmissionTreeCV, pretty = 0)
summary(pruneAdmissionTreeCV)


```


```{r, echo=FALSE}

set.seed(1000101010)
admission.rf <- randomForest(Chance.of.Admit~., data = admissionsTrain, importance = TRUE)
admission.rf
```

Since Random Forest uses out-of-bag which is similar to cross validation so no cross validation was performed. We can look at the importance of the variables.


```{r, echo=FALSE}
varImpPlot(admission.rf)
```

As seen from the Importance Plot the most important variables are CGPA, GRE Score and TOEFL scores when using chance of admission as a response variable. 


#Research

```{r, echo=FALSE}
set.seed(1388582293)
researchTree <- tree(Research~., data = admissionsTrain)
plot(researchTree)
text(researchTree, pretty=0)


researchTreeCV <- cv.tree(researchTree, FUN = prune.tree, K = 10)
plot(researchTreeCV, type = "b")
which.min(researchTreeCV$dev)
researchTreeCV$dev

researchTreeCV$dev
researchTreeCV$size
which.min(researchTreeCV$dev)
```

Cross Validation Suggests 3 terminal nodes would be best.

```{r, echo=FALSE}
pruneResearchTreeCV <- prune.tree(researchTree, best=3)
plot(pruneResearchTreeCV)
text(pruneResearchTreeCV, pretty = 0)
summary(pruneResearchTreeCV)
```

```{r, echo=FALSE}
set.seed(1413755523)
research.rf <- randomForest(Research~., data = admissionsTrain, importance = TRUE)
research.rf
varImpPlot(research.rf)

```


