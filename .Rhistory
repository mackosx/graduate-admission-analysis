#add in CGPA
add1(linear.null, ~. +CGPA, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR  + Research + University.Rating, test = "F")
#add in CGPA, GRE.Score
add1(linear.null, ~. +CGPA + GRE.Score , scope = ~  Serial.No. + TOEFL.Score + SOP + LOR  + Research + University.Rating, test = "F")
#add in CGPA, GRE.Score, TOEFL.Score
add1(linear.null, ~. +CGPA + GRE.Score + TOEFL.Score, scope = ~  Serial.No.  + SOP + LOR  + Research + University.Rating, test = "F")
add1(linear.null.rank, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + University.Rating, test = "F")
add1(linear.null.rank, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + University.Rating, test = "F")
add1(linear.null.rank, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + Chance.of.Admit, test = "F")
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
test <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (test)
head(test)
linear.full <- lm(Chance.of.Admit ~., data=test)
linear.null <- lm(Chance.of.Admit ~ 1, data=test)
linear.rank.full <- lm(University.Rating ~., data=test)
linear.null.full <- lm(University.Rating ~ 1, data=test)
linear <- lm(Chance.of.Admit ~., data=test)
summary(linear)
plot(linear)
linear <- lm(University.Rating ~., data=test)
summary(linear)
plot(linear)
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + University.Rating )
summary(linear)
#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research )
summary(linear)
#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research )
summary(linear)
add1(linear.null.rank, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + Chance.of.Admit, test = "F")
#summary (test)
head(test)
linear.null <- lm(Chance.of.Admit ~ 1, data=test)
linear.null.full <- lm(University.Rating ~ 1, data=test)
add1(linear.null.full, scope = ~  Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + Chance.of.Admit, test = "F")
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
test <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (test)
head(test)
linear.full <- lm(Chance.of.Admit ~., data=test)
linear.null <- lm(Chance.of.Admit ~ 1, data=test)
linear.rank.full <- lm(University.Rating ~., data=test)
linear.null.full <- lm(University.Rating ~ 1, data=test)
linear <- lm(Chance.of.Admit ~., data=test)
summary(linear)
plot(linear)
linear <- lm(University.Rating ~., data=test)
summary(linear)
plot(linear)
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP + LOR + CGPA + Research + University.Rating )
summary(linear)
#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research )
summary(linear)
#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research )
summary(linear)
install.packages("mclust")
install.packages("cluster")
knitr::opts_chunk$set(echo = TRUE)
card <- read.csv("car93.csv", stringsAsFactors = FALSE)
pcard <- prcomp(as.matrix(card[,-c(1,2,3,4)]), scale.=TRUE)
summary(pcard)
biplot(pcard)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
library(mclust)
library(cluster)
citation("mclust")
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
library(mclust)
library(cluster)
citation("mclust")
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
knitr::opts_chunk$set(echo = TRUE)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
animalsDist<-cmdscale(dAnimals)
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
card <- read.csv("car93.csv", stringsAsFactors = FALSE)
pcard <- prcomp(as.matrix(card[,-c(1,2,3,4)]), scale.=TRUE)
summary(pcard)
biplot(pcard)
plot(pcard, type="lines", main="Scree Plot")
library(neuralnet)
knitr::opts_chunk$set(echo = TRUE)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
animalsDist<-cmdscale(dAnimals)
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
#head(animals)
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster) #points(kAnimals$centers, col = 1:3, pch=8, cex=2)
kAnimals2<-kmeans(animalsDist, 3) plot(animalsDist, col = kAnimals2$cluster) points(kAnimals2$centers, col = 1:3, pch=8, cex=2)
knitr::opts_chunk$set(echo = TRUE)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
animalsDist<-cmdscale(dAnimals)
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
#head(animals)
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster) #points(kAnimals$centers, col = 1:3, pch=8, cex=2)
kAnimals2<-kmeans(animalsDist, 3)
plot(animalsDist, col = kAnimals2$cluster) points(kAnimals2$centers, col = 1:3, pch=8, cex=2)
knitr::opts_chunk$set(echo = TRUE)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
animalsDist<-cmdscale(dAnimals)
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
#head(animals)
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster) #points(kAnimals$centers, col = 1:3, pch=8, cex=2)
kAnimals2<-kmeans(animalsDist, 3)
plot(animalsDist, col = kAnimals2$cluster)
points(kAnimals2$centers, col = 1:3, pch=8, cex=2)
#kAnimals2$cluster
table(rownames(animals), kAnimals2$cluster)
card <- read.csv("car93.csv", stringsAsFactors = FALSE)
pcard <- prcomp(as.matrix(card[,-c(1,2,3,4)]), scale.=TRUE)
summary(pcard)
biplot(pcard)
plot(pcard, type="lines", main="Scree Plot")
library(neuralnet)
plot(pcard, type="lines", main="Scree Plot")
knitr::opts_chunk$set(echo = TRUE)
library(mclust)
library(cluster)
data("animals")
dAnimals <- daisy(animals)
summary(dAnimals)
animalsDist<-cmdscale(dAnimals)
plot(animalsDist, type = "n")
text(animalsDist, rownames(animalsDist))
#head(animals)
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster) #points(kAnimals$centers, col = 1:3, pch=8, cex=2)
kAnimals2<-kmeans(animalsDist, 3)
plot(animalsDist, col = kAnimals2$cluster)
points(kAnimals2$centers, col = 1:3, pch=8, cex=2)
#kAnimals2$cluster
table(rownames(animals), kAnimals2$cluster)
card <- read.csv("car93.csv", stringsAsFactors = FALSE)
pcard <- prcomp(as.matrix(card[,-c(1,2,3,4)]), scale.=TRUE)
summary(pcard)
biplot(pcard)
round(carPCA$rotation[,1],2)
install.packages("neuralnet")
install.packages("NeuralNetTools")
install.packages("randomForest")
install.packages("HSAUR2")
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(mvtnorm)
library(mclust)
library(cluster)
library(fpc)
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(mvtnorm)
library(mclust)
library(cluster)
#library(fpc)
library(boot)
library(tree)
library(MASS)
library(randomForest)
admissionsData <- read.csv("Admission_Predict_Ver1.1.csv")
#summary (admissionsData)
attach(admissionsData)
#Admission_Predict_Ver1.1 <- read.csv("~/Google Drive/Year 3 - S2 Class Files/DATA 311/Project/graduate-admissions/Admission_Predict_Ver1.1.csv")
#View(Admission_Predict_Ver1.1)
head(admissionsData[,-1])
dg<-daisy(admissionsData, metric="gower")
pdist <- cmdscale(d=dg)
plot(pdist)
hms <- hclust(na.omit(dg), method="single")
#plot(hms)
pairs(pdist, col=cutree(hms,2))
#plot(pdist)
pairs(admissionsData, col=cutree(hms,2))
set.seed(43849)
#remove Chance.of.Admit (Response variable, position 9) and Serial.No (unique identifier, position 1)
pca.admin <- prcomp(as.matrix(admissionsData[,-c(1,9)]), scale = TRUE)
summary(pca.admin)
plot(pca.admin, type="lines")
biplot(pca.admin)
plot(pca.admin$x[,1:2], type = "n")
text(pca.admin$x[,1:2], labels = 1:nrow(admissionsData))
round(pca.admin$rotation[,1:2], 2)
admissionsData[order(pca.admin$x[,1], decreasing = TRUE)[1:4],1:9]
admissionsData[order(pca.admin$x[,2], decreasing = TRUE)[1:4], 1:9]
set.seed(43849)
pca.admin2 <- prcomp(as.matrix(admissionsData[,-c(1,8)]), scale = TRUE)
summary(pca.admin2)
plot(pca.admin2, type="lines")
biplot(pca.admin2)
plot(pca.admin2$x[,1:2], type = "n")
text(pca.admin2$x[,1:2], labels = 1:nrow(admissionsData))
round(pca.admin2$rotation[,1:2], 2)
admissionsData[order(pca.admin2$x[,1], decreasing = TRUE)[1:4],1:9]
admissionsData[order(pca.admin2$x[,2], decreasing = TRUE)[1:4], 1:9]
University.Rating <- factor(University.Rating)
Research <- factor(Research)
logmod <- glm(University.Rating ~., data=admissionsData)
summary(logmod)
plot(logmod)
linear.full <- lm(Chance.of.Admit ~., data=admissionsData)
linear.null <- lm(Chance.of.Admit ~ 1, data=admissionsData)
linear.rank.full <- lm(University.Rating ~., data=admissionsData)
linear.null.full <- lm(University.Rating ~ 1, data=admissionsData)
linear <- lm(Chance.of.Admit ~., data=admissionsData)
summary(linear)
plot(linear)
# Other useful functions
coefficients(linear) # model coefficients
confint(linear, level=0.95) # CIs for model parameters
fitted(linear) # predicted values
residuals(linear) # residuals
anova(linear) # anova table
vcov(linear) # covariance matrix for model parameters
influence(linear) # regression diagnostics
linear <- lm(Chance.of.Admit~ ., data = admissionsData )
summary(linear)
#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = admissionsData )
summary(linear)
#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = admissionsData )
#All variables are now significant
summary(linear)
set.seed(7861)
cvlm <- list()
msecv <- NA
coef <-matrix(nrow = 500, ncol=length(linear$coefficients))
for(i in 1:nrow(admissionsData)){
#Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[-i])^2
#coef[[i]] <- cvlm[[i]]$coefficients
for(j in 1:length(linear$coefficients)){
coef[i,j] <- cvlm[[i]]$coefficients[j]
}
#msecv[i]
}
#output mean of MSE
mean(msecv)
newboots <- list()
bootsmod <- list()
msebs <- NA
B <- 5000
bootcoef <- matrix(nrow = B, ncol=length(linear$coefficients))
for(i in 1:B){
newboots[[i]] <- admissionsData[sample(1:nrow(admissionsData), nrow(admissionsData), replace=TRUE),]
bootsmod[[i]] <- lm(Chance.of.Admit~GRE.Score + TOEFL.Score +LOR + CGPA + Research, data=newboots[[i]])
for(j in 1:length(linear$coefficients)){
bootcoef[i,j] <- bootsmod[[i]]$coefficients[j]
}
#msebs[i] <- (predict(bootsmod[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
}
summary(linear)$coefficients[,2]
c(sd(bootcoef[,1]),sd(bootcoef[,2]),sd(bootcoef[,3]),sd(bootcoef[,4]),sd(bootcoef[,5]),sd(bootcoef[,6]),sd(bootcoef[,7]))
c(sd(coef[,1]),sd(coef[,2]),sd(coef[,3]),sd(coef[,4]),sd(coef[,5]),sd(coef[,6]),sd(coef[,7]))
knitr::opts_chunk$set(echo = TRUE)
linear <- lm(Chance.of.Admit~ ., data = test )
#summary(linear)
#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = test )
#summary(linear)
#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ Serial.No. + GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = test )
#All variables are now significant
summary(linear)
plot(linear)
logmod <- glm(Research~., data=test)
summary(logmod)
plot(logmod)
#Removed LOR
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP + CGPA, data=test)
summary(logmod)
#plot(logmod)
#Removed LOR, CGPA
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating + SOP , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL, SOP
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL, SOP, Serial Number
logmod <- glm(Research~ GRE.Score  + University.Rating , data=test)
summary(logmod)
#plot(logmod)
ResearchData <- test$Research
ResearchDataFactor <- factor(test$Research)
simlog<-glm(factor(Research)~., family = "binomial", data = test)
table(predict(simlog, type = "response")>0.5, ResearchData)
misclassificationRate <- (57+66)/(154+223)
capture.output(cat('Misclassification rate = ', misclassificationRate))
library(MLmetrics)
F1<- F1_Score(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Accu <- Accuracy(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Sens <- Sensitivity(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
scoreTable <-cbind(F1, Accu, Sens)
colnames(scoreTable)<-c("F1 Score", "Accuracy", "Sensitivity")
rownames(scoreTable)<-c("Logistic Regression")
#rownames(scoreTable)<-c("Logistic Regression", "Neural Network")
round(scoreTable,3)
test <- read.csv("Admission_Predict_Ver1.1.csv")
summary (test)
head(test)
attach(test)
#Linear Regression and some plots
#Here's a linear model (Chance of Admit)
linear <- lm(Chance.of.Admit ~., data=test)
#summary(linear)
#plot(linear)
#Here's a linear model (University Rating)
linear <- lm(University.Rating ~., data=test)
#summary(linear)
#plot(linear)
logmod <- glm(Research~., data=test)
#summary(logmod)
#plot(logmod)
chance.vs.CGPA <- lm(test$Chance.of.Admit ~ test$CGPA)
plot(test$Chance.of.Admit ~ test$CGPA, xlab = "Chance of Admission", ylab = "CGPA", main = "Chance of Admission VS CGPA")
abline(chance.vs.CGPA , col="red", lwd=3, data = test)
#sum (predict(chance.vs.CGPA, data.frame(test)))
set.seed(7861)
cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
#Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(Serial.No.[-i] + GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
set.seed(7861)
cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
#Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame( GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
set.seed(7861)
cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
#Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~  CGPA[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame(CGPA[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
linear <- lm(Chance.of.Admit~ ., data = test )
#summary(linear)
#Remove University Ranking because it has the highest non significant p value
linear <- lm(Chance.of.Admit~ GRE.Score + TOEFL.Score + SOP +LOR + CGPA + Research , data = test )
#summary(linear)
#Remove SOP has the second highest non significant p value
linear <- lm(Chance.of.Admit~ GRE.Score + TOEFL.Score +LOR + CGPA + Research , data = test )
#All variables are now significant
summary(linear)
plot(linear)
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP +LOR + CGPA, data = test )
#summary(linear)
#Remove SOP
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR + CGPA, data = test )
#summary(linear)
#Remove SOP, CGPA
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating  +LOR, data = test )
#summary(linear)
#Remove SOP, CGPA, LOR
linear <- lm(Research~ Serial.No. + GRE.Score + TOEFL.Score + University.Rating, data = test )
#summary(linear)
#Remove SOP, CGPA, LOR, TOEFL
linear <- lm(Research~ Serial.No. + GRE.Score + University.Rating, data = test )
#summary(linear)
#Remove SOP, CGPA, LOR, TOEFL, Serial Number
linear <- lm(Research~ + GRE.Score + University.Rating, data = test )
summary(linear)
plot(linear)
logmod <- glm(Research~., data=test)
summary(logmod)
plot(logmod)
#Removed LOR
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP + CGPA, data=test)
summary(logmod)
#plot(logmod)
#Removed LOR, CGPA
logmod <- glm(Research~Serial.No. + GRE.Score + TOEFL.Score + University.Rating + SOP , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating + SOP , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL, SOP
logmod <- glm(Research~Serial.No. + GRE.Score  + University.Rating , data=test)
summary(logmod)
#Removed LOR, CGPA, TOEFL, SOP, Serial Number
logmod <- glm(Research~ GRE.Score  + University.Rating , data=test)
summary(logmod)
#plot(logmod)
set.seed(7861)
cvlm <- list()
msecv <- NA
for(i in 1:nrow(test)){
#Fit the linear model
cvlm[[i]] <- lm(Chance.of.Admit[-i] ~ GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i])
# Calculate MSE for ith model
msecv[i] <- (predict(cvlm[[i]], newdata = data.frame( GRE.Score[-i] + TOEFL.Score[-i] +LOR[-i] + CGPA[-i] + Research[-i]))-Chance.of.Admit[i])^2
#msecv[i]
}
#output mean of MSE
mean(msecv)
?glm
ResearchData <- test$Research
ResearchDataFactor <- factor(test$Research)
simlog<-glm(factor(Research)~., family = "binomial", data = test)
table(predict(simlog, type = "response")>0.5, ResearchData)
misclassificationRate <- (57+66)/(154+223)
capture.output(cat('Misclassification rate = ', misclassificationRate))
library(MLmetrics)
F1<- F1_Score(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Accu <- Accuracy(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Sens <- Sensitivity(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
scoreTable <-cbind(F1, Accu, Sens)
colnames(scoreTable)<-c("F1 Score", "Accuracy", "Sensitivity")
rownames(scoreTable)<-c("Logistic Regression")
#rownames(scoreTable)<-c("Logistic Regression", "Neural Network")
round(scoreTable,3)
ResearchData <- test$Research
ResearchDataFactor <- factor(test$Research)
simlog<-glm(factor(Research)~., family = "binomial", data = test)
table(predict(simlog, type = "response")>0.5, ResearchData)
misclassificationRate <- (57+66)/(154+223)
capture.output(cat('Misclassification rate = ', misclassificationRate))
library(MLmetrics)
F1<- F1_Score(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Accu <- Accuracy(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Sens <- Sensitivity(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
scoreTable <-cbind(F1, Accu, Sens)
colnames(scoreTable)<-c("F1 Score", "Accuracy", "Sensitivity")
rownames(scoreTable)<-c("Logistic Regression")
#rownames(scoreTable)<-c("Logistic Regression", "Neural Network")
round(scoreTable,3)
ResearchData <- test$Research
ResearchDataFactor <- factor(test$Research)
simlog<-glm(factor(Research)~., family = "binomial", data = test)
table(predict(simlog, type = "response")>0.5, ResearchData)
misclassificationRate <- (57+66)/(154+223)
capture.output(cat('Misclassification rate = ', misclassificationRate))
library(MLmetrics)
F1<- F1_Score(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Accu <- Accuracy(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
Sens <- Sensitivity(as.numeric(predict(simlog, type = "response")>0.5), ResearchData)
scoreTable <-cbind(F1, Accu, Sens, misclassificationRate)
colnames(scoreTable)<-c("F1 Score", "Accuracy", "Sensitivity", "Misclassification")
rownames(scoreTable)<-c("Logistic Regression")
#rownames(scoreTable)<-c("Logistic Regression", "Neural Network")
round(scoreTable,3)
